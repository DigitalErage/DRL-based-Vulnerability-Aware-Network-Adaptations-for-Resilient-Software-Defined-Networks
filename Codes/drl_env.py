import torch
from anytree import NodeMixin
from copy import deepcopy
import math
import random
import numpy as np

#p_s = 0
#detection_rate = 1
#b = 800
#indicator = np.random.rand(b+1, b+1)
#evals = np.load('evals_0.30,0.5,5.npy')

def get_next(area,action):
    x1, y1, x2, y2, x3, y3 = area
    if action == 0:
        x1, y1, x2, y2, x3, y3 = (x1+x2)/2, (y1+y2)/2, x2, y2, (x2+x3)/2, (y2+y3)/2
        area = [x1, y1, x2, y2, x3, y3]
        state = [(x1+x2+x3)/3, (y1+y2+y3)/3]
        return area, state
    elif action == 1:
        x1, y1, x2, y2, x3, y3 = x1, y1, (x1+x2)/2, (y1+y2)/2, (x1+x3)/2, (y1+y3)/2
        area = [x1, y1, x2, y2, x3, y3]
        state = [(x1+x2+x3)/3, (y1+y2+y3)/3]
        return area, state
    elif action == 2:
        x1, y1, x2, y2, x3, y3 = (x2+x3)/2, (y2+y3)/2, (x1+x3)/2, (y1+y3)/2, (x1+x2)/2, (y1+y2)/2
        area = [x1, y1, x2, y2, x3, y3]
        state = [(x1+x2+x3)/3, (y1+y2+y3)/3]
        return area, state
    elif action == 3:
        x1, y1, x2, y2, x3, y3 = (x1+x3)/2, (y1+y3)/2, (x2+x3)/2, (y2+y3)/2, x3, y3
        area = [x1, y1, x2, y2, x3, y3]
        state = [(x1+x2+x3)/3, (y1+y2+y3)/3]
        return area, state
    
class ENV(object):
    def __init__(self, agent, area=None):
        self.area_0 = area
        self.area = deepcopy(self.area_0)
        self.center_0 = np.array([(self.area_0[0]+self.area_0[2]+self.area_0[4])/3,
                                (self.area_0[1]+self.area_0[3]+self.area_0[5])/3],dtype=float)
        self.length = max(abs(self.area[0]-self.area[2]),abs(self.area[0]-self.area[4]),abs(self.area[2]-self.area[4]),abs(self.area[1]-self.area[3]),abs(self.area[1]-self.area[5]),abs(self.area[3]-self.area[5]))
        self.state = np.array([0]*math.ceil(math.log(self.length,2)))
        self.steps = 0
        self.action_space = np.array([0,1,2,3],dtype=int)
        self.agent = agent
        self.centers = []
        temp_size = int(max(area))+1
        self.indicator = np.random.rand(temp_size, temp_size)
        
    def reset(self):
        self.area = deepcopy(self.area_0)
        self.center = deepcopy(self.center_0)
        self.steps = 0
        self.state = np.array([0]*math.ceil(math.log(self.length,2)))
        self.centers = []
        return self.state
    
    def step(self,action,precision = 5,eval_set1 = set(),eval_set2 = set()):
        done = False
        #x,y = round(self.center[0]), round(self.center[1])
        #real_cf = self.agent.eval_all(budget=[x,y])#evals[x,y]#self.agent.eval_all(budget=[x,y])
        '''if random.random() < p_s:
            if random.random() < detection_rate:
                current_f = indicator[x,y]
            else:
                indicator[x,y] = random.random()
                current_f = indicator[x,y]
        else:
            indicator[x,y] = real_cf
            current_f = indicator[x,y]'''
        #print(self.area)
        self.area,self.center = get_next(self.area,action)
        x,y = round(self.center[0]), round(self.center[1])
        self.centers.append([x,y])
        #print(1,len(self.centers))
        #real_nf = self.agent.eval_all(budget=[x,y])#evals[x,y]#self.agent.eval_all(budget=[x,y])
        '''if random.random() < p_s:
            if random.random() < detection_rate:
                next_f = indicator[x,y]
            else:
                indicator[x,y] = random.random()
                next_f = indicator[x,y]
        else:
            indicator[x,y] = real_nf
            next_f = indicator[x,y]'''
        self.state[self.steps] = action + 1
        self.steps += 1
        if abs(self.area[1]-self.area[3])<=1:
            done = True
        #print(self.area)
        #real_r = real_nf - real_cf
        #r = next_f - current_f
        if done:
            #print(len(self.centers))
            x,y = self.centers[-1]
            #eval_set1.add((x, y))
            #eval_set2.add(x)
            r = self.agent.eval_all(budget=[x,y])
        else:
            r = 0
        return self.state, r, done#, eval_set1, eval_set2
    
    def skip_step(self,action,r,args):
        done = False
        #x,y = round(self.center[0]), round(self.center[1])
        self.area,self.center = get_next(self.area,action)
        x,y = round(self.center[0]), round(self.center[1])
        self.centers.append([x,y])
        #print(2,len(self.centers))
        self.state[self.steps] = action + 1
        self.steps += 1
        if abs(self.area[1]-self.area[3])<=1:
            done = True
            if random.random() < args.p_s:
                if random.random() < args.d_r:
                    r = self.indicator[x,y]
                else:
                    self.indicator[x,y] = random.random()
                    r = self.indicator[x,y]
        return self.state, r, done, (x,y)
    
class ReplayBuffer(object):
    def __init__(self, capacity):
        self.capacity = capacity
        self.buffer = []

    def add(self, s0, a, r, s1, done):
        if len(self.buffer) >= self.capacity:
            self.buffer.pop(0)
        self.buffer.append((s0, a, r, s1, done))

    def sample_old(self, batch_size):
        s0, a, r, s1, done = zip(*random.sample(self.buffer, batch_size))
        s0 = torch.tensor(s0, dtype=torch.float).cuda()
        s1 = torch.tensor(s1, dtype=torch.float).cuda()
        a = torch.tensor(a, dtype=torch.long).cuda()
        r = torch.tensor(r, dtype=torch.float).cuda()
        done = torch.tensor(done, dtype=torch.float).cuda()
        return s0, a, r, s1, done
    
    def sample(self):
        s0, a, r, s1, done = zip(*self.buffer)
        s0 = torch.tensor(s0, dtype=torch.float).cuda()
        s1 = torch.tensor(s1, dtype=torch.float).cuda()
        a = torch.tensor(a, dtype=torch.long).cuda()
        r = torch.tensor(r, dtype=torch.float).cuda()
        done = torch.tensor(done, dtype=torch.float).cuda()
        self.buffer = []
        return s0, a, r, s1, done

    def size(self):
        return len(self.buffer)
    
class node(NodeMixin):  # Add Node feature
    def __init__(self, past_actions, reward, parent=None, children=None):
        super(node, self).__init__()
        self.past_actions = past_actions
        self.reward = reward
        self.parent = parent
        self.children = []
        if children:
            self.children.append(children)
    def add_children(self, children):
        self.children.append(children)
        
def actions_to_str(actions):
    return ''.join(map(str, actions))
