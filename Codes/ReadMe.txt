The code base is a part of the source codes of the paper entitled "EVADE: Efficient Moving Target Defense for Autonomous Network Topology Shuffling Using Deep Reinforcement Learning". This paper is published in ACNS2023.

To reproduce the results for proposed DRL schemes, please follow these steps:
1: run "pre_eval.py" and "rpre_eval.py" to collect pretrain data
2: run "mtd.py" to do training

You can customize the environment with different arguments:

--train_times type=int default=100 help='DRL training times/epoches'
--attack_times type=int default=500 help='attack simulation times'
--l type=int default=5 help='number of software versions'
--lmd type=float default=2 help='exponential(poisson) distribution parameter'
--b type=int default=800 help='budget'
--p_s type=float default=0.3 help='state manupulation attack probability'
--d_r type=float default=0.8 help='detection rate for state manupulation attack'
--model type=str default="ppo" help="DRL model(dqn/ppo)"
--greedy type=int default=1 help="gready enabled/disabled(1/0)"
--drl type=int default=1 help="drl enabled/disabled(1/0)"
--rn type=int default=0 help="real network enabled/disabled(1/0)"

To run other baseline schemes, including "GA" and "Random", please refer to "mtd_ga.py" and "mtd_random.py" respectively.
