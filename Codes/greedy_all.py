import numpy as np
from multiprocessing import Pool
import math

#subdivide triangle if the middle point is unzero (could further decrease precision)
def get_area(pt, length, threshold = 128):
    x2, y2 = pt
    if x2 > 0:
        budget = min(length-1-x2, threshold)
        density1 = min(x2,threshold/2)
        density2 = min(length-1-x2, threshold/2)
        x1,y1,x2,y2,x3,y3 = x2-density1,0,x2+budget/2,y2+budget/2,x2+density2,0
        if x3-x1>=2 and y2>=2:
            return x1,y1,x2,y2,x3,y3
        else:
            return False
    elif y2 > 0:        
        budget = min(length-1-y2, threshold)
        density1 = min(y2,threshold/2)
        density2 = min(length-1-y2, threshold/2)
        x1,y1,x2,y2,x3,y3 = 0,y2-density1,x2+budget/2,y2+budget/2,0,y2+density2
        if x2>=2 and y3-y1>=2:
            return x1,y1,x2,y2,x3,y3
        else:
            return False
    else:
        return False
    
def multi_evaluate(agent, input_array):
    pool = Pool()
    #print("Separated results:")
    input_array = [[i] for i in input_array]
    results = pool.starmap(agent.eval_all, input_array)
    pool.close()
    pool.join()
    return results

def greedy(agent, length, step=20, get_graph=False):
    step = max(1,min(length,math.ceil(length/step)))
    list1 = list(range(0,length,step))
    budgets_eval = [[i,0] for i in list1] + [[0,i] for i in list1[1:]]
    if len(budgets_eval) == 0:
        return False
    rewards = multi_evaluate(agent, budgets_eval)
    #print(budgets_eval,rewards)
    idx = np.argmax(np.array(rewards))
    if get_graph:
        return agent.eval_all(budgets_eval[idx],get_graph=True)
    area = get_area(budgets_eval[idx], length)
    return area

#optimize density
def greedy_old(agent, length, step=20):
    max_check = step
    step = int(length/step)
    list1 = list(range(0,length,step))
    list2 = list(range(0,-length,-step))
    indices = list1[::-1]+list2[1:]
    current = agent.eval_all(budget=[indices[0],0],multi=True)
    count = 0
    max_r,max_idx = current,indices[0]
    for i in indices[1:]:
        if count > max_check/10:
            #print(indices.index(i))
            break
        if i>0:
            next_ = agent.eval_all(budget=[i,0],multi=True)
            if next_ > max_r:
                count = 0
                max_r,max_idx = next_,i
                #print(max_r,max_idx)
            else:
                count += 1
            current = next_
        if i<0:
            next_ = agent.eval_all(budget=[0,-i],multi=True)
            if next_ > max_r:
                count = 0
                max_r,max_idx = next_,i
                #print(max_r,max_idx)
            else:
                count += 1
            current = next_
    interval = [max_idx-step, max_idx, max_idx+step]
    if interval[1]>0:
        budget = [interval[1],0]
        g = agent.eval_all(budget=budget,multi=True,get_graph=True)
    else:
        budget = [0,-interval[1]]
        g = agent.eval_all(budget=budget,multi=True,get_graph=True)
    area = get_area(interval, length)
    return area, g

def greedy_old(agent,length):
    total = 0
    sim_times = 1
    action_seq = []
    for i in range(sim_times):
        area = [0,length,0,0,length,0]
        while abs(area[2]-area[4])>1:
            max_area,max_state = get_next(area,0)
            x,y = round(max_state[0]), round(max_state[1])
            max_f = agent.eval_all(budget=[x,y],multi=True)
            max_action = 0
            for action in range(1,4):
                temp_area,state = get_next(area,action)
                x,y = round(state[0]), round(state[1])
                temp = agent.eval_all(budget=[x,y],multi=True)
                if temp>max_f:
                    max_state = state
                    max_f = temp
                    max_area = temp_area
                    max_action = action
            area = max_area
            print(round(max_state[0]), round(max_state[1]), max_action, max_area, max_f)
            action_seq.append(max_action)
        x,y = round(max_state[0]), round(max_state[1])
        real_f = agent.eval_all(budget=[x,y])
        total += real_f
    return x, y, total/sim_times, action_seq

def get_area_old(area,action_list):
    for action in action_list:
        area,state = get_next(area,action)
    return area

def get_hot_area(hot_map, threshold = 0.5, length = 252):
    area_0 = [0,length,0,0,length,0]
    hot_actions = []
    temp_map = hot_map
    total = len(hot_map)
    for i in range(hot_map.shape[1]):
        temp = temp_map[:,i]
        unique, counts = np.unique(temp, return_counts=True)
        idx = np.argmax(counts)
        if counts[idx] > threshold*total:
            temp_map = temp_map[np.where(temp_map[:,i]==unique[idx])[0]]
            hot_actions.append(unique[idx])
        else:
            return get_area(area_0,hot_actions), hot_actions
    return get_area(area_0,hot_actions), hot_actions

#transform budget to adapted graph
def budget_to_graph(agent, budget):
    return agent.eval_all(budget=budget,get_graph=True)

def use_greedy(agent, results, length = 252):
    hot_map = np.array([results[i][-1] for i in range(len(results))])
    evals = np.array([results[i][-2] for i in range(len(results))])
    budgets = np.array([results[i][:2] for i in range(len(results))])
    hot_area, hot_actions = get_hot_area(hot_map, threshold = 0.7, length = 252)
    len_act = len(hot_actions)
    print(hot_actions)
    if len_act>-1:#>1
        idx = [np.array_equal(hot_map[i,:len_act],hot_actions) for i in range(len(hot_map))]
        temp_evals = evals[idx]
        temp_budgets = budgets[idx]
        budget = temp_budgets[np.argsort(temp_evals)[0]]
        graph = budget_to_graph(agent,budget)
        return graph, hot_area
    else:
        return False, hot_area#drl
